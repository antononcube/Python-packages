{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e670c70c3b6efd4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# LLMPrompts Python package\n",
    "\n",
    "## In brief\n",
    "\n",
    "This Python package provides data and functions for facilitating the creation, storage, retrieval, and curation of \n",
    "[Large Language Models (LLM) prompts](https://en.wikipedia.org/wiki/Prompt_engineering).\n",
    "\n",
    "--------\n",
    "\n",
    "## Installation\n",
    "\n",
    "### Install from GitHub\n",
    "\n",
    "```shell\n",
    "pip install -e git+https://github.com/antononcube/Python-packages.git#egg=LLMPrompts-antononcube\\&subdirectory=LLMPrompts\n",
    "```\n",
    "\n",
    "### From PyPi\n",
    "\n",
    "```shell\n",
    "pip install LLMPrompts\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f4777f611df8fc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "------\n",
    "\n",
    "## Basic usage examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf134200c48a4f15",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Load the packages \"LLMPrompts\", [AAp1], and \"LLMFunctionObjects\", [AAp2]:"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prompt data retrieval\n",
    "\n",
    "Here the LLM prompt and function packages are loaded: "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "622dee682a468c1f"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd61142dd9e2e3c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T18:40:09.974208Z",
     "start_time": "2023-09-26T18:40:09.690323Z"
    }
   },
   "outputs": [],
   "source": [
    "from LLMPrompts import *\n",
    "from LLMFunctionObjects import *"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is a prompt data retrieval using a regex:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d1f5898ea0b4665"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b49a9835",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T18:40:09.981908Z",
     "start_time": "2023-09-26T18:40:09.978451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'NarrativeToResume': 'Rewrite narrative text as a resume',\n 'NothingElse': 'Give output in specified form, no other additions'}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_prompt_data(r'^N.*e$', fields=\"Description\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Retrieve a prompt with a specified name and related data fields:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b803d2ce9fa14bb"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c92cacf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T18:40:09.986384Z",
     "start_time": "2023-09-26T18:40:09.981614Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'Yoda': ['Respond as Yoda, you will',\n  'You are Yoda. \\nRespond to ALL inputs in the voice of Yoda from Star Wars. \\nBe sure to ALWAYS use his distinctive style and syntax. Vary sentence length.']}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_prompt_data(\"Yoda\", fields=['Description', \"PromptText\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is number of all prompt names: "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b50f05e9272e0a56"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9601420",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T18:40:09.987143Z",
     "start_time": "2023-09-26T18:40:09.984288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "154"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(llm_prompt_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is a data frame with all prompts names and descriptions:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1677aca9ff426b3c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                        Name  \\\n0    19thCenturyBritishNovel   \n1            AbstractConvert   \n2        ActiveVoiceRephrase   \n3       AlternativeHistorian   \n4                AnimalSpeak   \n..                       ...   \n149          FriendlySnowman   \n150          HugoAwardWinner   \n151              ShortLineIt   \n152                 Unhedged   \n153              WordGuesser   \n\n                                           Description  \n0    You know that AI could as soon forget you as m...  \n1                        Convert text into an abstract  \n2         Rephrase text from passive into active voice  \n3                Explore alternate versions of history  \n4                      The language of beasts, sort of  \n..                                                 ...  \n149                                Chat with a snowman  \n150  Write a science fiction novel about climate ch...  \n151                  Format text to have shorter lines  \n152            Rewrite a sentence to be more assertive  \n153                           Play a word game with AI  \n\n[154 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19thCenturyBritishNovel</td>\n      <td>You know that AI could as soon forget you as m...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AbstractConvert</td>\n      <td>Convert text into an abstract</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ActiveVoiceRephrase</td>\n      <td>Rephrase text from passive into active voice</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AlternativeHistorian</td>\n      <td>Explore alternate versions of history</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AnimalSpeak</td>\n      <td>The language of beasts, sort of</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>FriendlySnowman</td>\n      <td>Chat with a snowman</td>\n    </tr>\n    <tr>\n      <th>150</th>\n      <td>HugoAwardWinner</td>\n      <td>Write a science fiction novel about climate ch...</td>\n    </tr>\n    <tr>\n      <th>151</th>\n      <td>ShortLineIt</td>\n      <td>Format text to have shorter lines</td>\n    </tr>\n    <tr>\n      <th>152</th>\n      <td>Unhedged</td>\n      <td>Rewrite a sentence to be more assertive</td>\n    </tr>\n    <tr>\n      <th>153</th>\n      <td>WordGuesser</td>\n      <td>Play a word game with AI</td>\n    </tr>\n  </tbody>\n</table>\n<p>154 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "dfPrompts = pandas.DataFrame([dict(zip([\"Name\", \"Description\"], x)) for x in llm_prompt_data(fields=[\"Name\", \"Description\"]).values()])\n",
    "dfPrompts"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T18:40:09.996028Z",
     "start_time": "2023-09-26T18:40:09.989865Z"
    }
   },
   "id": "48559ab35048998e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Code generating function"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80cdc57c416ed5c1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is an LLM function creation if a code writing prompt that takes target language as an argument: "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55733c0f15d8d874"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aa69b0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T18:40:10.031172Z",
     "start_time": "2023-09-26T18:40:09.995520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'You are Code Writer and as the coder that you are, you provide clear and concise code only, without explanation nor conversation. \\nYour job is to output code with no accompanying text.\\nDo not explain any code unless asked. Do not provide summaries unless asked.\\nYou are the best Python programmer in the world but do not converse.\\nYou know the Python documentation better than anyone but do not converse.\\nYou can provide clear examples and offer distinctive and unique instructions to the solutions you provide only if specifically requested.\\nOnly code in Python unless told otherwise.\\nUnless they ask, you will only give code.'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcw = llm_function(llm_prompt(\"CodeWriterX\")(\"Python\"), e='ChatGPT')\n",
    "fcw.prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is a code generation request with that function:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92c41bfdae764153"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e8e542c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T18:40:13.316113Z",
     "start_time": "2023-09-26T18:40:09.998492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import random\n",
      "\n",
      "def random_walk(n):\n",
      "    x, y = 0, 0\n",
      "    for _ in range(n):\n",
      "        dx, dy = random.choice([(0,1), (0,-1), (1,0), (-1,0)])\n",
      "        x += dx\n",
      "        y += dy\n",
      "    return (x, y)\n"
     ]
    }
   ],
   "source": [
    "print(fcw(\"Random walk simulation.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fixing function"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7a073beb0f24d6e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using a function prompt retrieved with \"FTFY\" over the a misspelled word:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4061e5e560fc07e7"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "'Find and correct grammar and spelling mistakes in the following text.\\nResponse with the corrected text and nothing else.\\nProvide no context for the corrections, only correct the text.\\ninvokation'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_prompt(\"FTFY\")(\"invokation\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T18:40:13.316387Z",
     "start_time": "2023-09-26T18:40:13.311740Z"
    }
   },
   "id": "af462b8af84880f3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is the corresponding LLM function:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "985891d32d6db796"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f667c5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T18:40:13.622638Z",
     "start_time": "2023-09-26T18:40:13.316541Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n\\nWhere were we?'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fFTFY = llm_function(llm_prompt(\"FTFY\"))\n",
    "fFTFY(\"wher was we?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is modifier prompt with two arguments: "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54742c4a8ee4ae7e"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a9b0235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T18:40:13.622940Z",
     "start_time": "2023-09-26T18:40:13.619072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Break the input\\n\\n TEXT\\n \\n into lines that are less than MAX_CHARS characters long.\\n Do not otherwise modify the input. Do not add other text.'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_prompt(\"ShortLineIt\")(\"MAX_CHARS\", \"TEXT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is the corresponding LLM function:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1ac3b52946fccc8"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9767160c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T18:40:13.629546Z",
     "start_time": "2023-09-26T18:40:13.623408Z"
    }
   },
   "outputs": [],
   "source": [
    "fb = llm_function(llm_prompt(\"ShortLineIt\")(\"70\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is longish text:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a96085012250601"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8fc945f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T18:40:13.629738Z",
     "start_time": "2023-09-26T18:40:13.626723Z"
    }
   },
   "outputs": [],
   "source": [
    "text = 'A random walk simulation is a type of simulation that models the behavior of a random walk. A random walk is a mathematical process in which a set of steps is taken in a random order. The steps can be in any direction, and the order of the steps is determined by a random number generator. The random walk simulation is used to model a variety of real-world phenomena, such as the movement of particles in a gas or the behavior of stock prices. The random walk simulation is also used to study the behavior of complex systems, such as the spread of disease or the behavior of traffic on a highway.'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is the application of \"ShortLineIT\" applied to the text above:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8e5a71c69ce7bd1"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f198ae3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T18:40:14.848050Z",
     "start_time": "2023-09-26T18:40:13.629797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A random walk simulation is a type of simulation that models the behavior of a\n",
      "random walk. A random walk is a mathematical process in which a set of steps is\n",
      "taken in a random order. The steps can be in any direction, and the order of the\n",
      "steps is determined by a random number generator. The random walk simulation is\n",
      "used to model a variety of real-world phenomena, such as the movement of\n",
      "particles in a gas or the behavior of stock prices. The random walk simulation\n",
      "is also used to study the behavior of complex systems, such as the spread of\n",
      "disease or the behavior of traffic on a highway.\n"
     ]
    }
   ],
   "source": [
    "print(fb(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Chat object creation with a prompt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a5ba2536a2b2965"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here a chat object is create with a person prompt:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d219f0e2cbb08f3"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19ec6511",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T18:40:14.853354Z",
     "start_time": "2023-09-26T18:40:14.848238Z"
    }
   },
   "outputs": [],
   "source": [
    "chatObj = llm_chat(llm_prompt(\"MadHatter\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Send a message:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac5beb279f0ac823"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "'Ah, my dear curious soul, I am the Mad Hatter, the one and only! A whimsical creature, forever lost in the realm of absurdity and tea time. I am here to entertain and perplex, to dance with words and sprinkle madness in the air. So, tell me, my friend, what brings you to my peculiar tea party today?'"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatObj.eval(\"Who are you?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T18:40:18.134573Z",
     "start_time": "2023-09-26T18:40:14.850553Z"
    }
   },
   "id": "2f26f1a7709d82e1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Send another message:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c57bb61a0091ee7"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "'Ah, oolong tea, a splendid choice indeed! The leaves unfurl, dancing in the hot water, releasing their delicate flavors into the air. And a chocolate, you say? How delightful! A sweet morsel to accompany the swirling warmth of the tea. But, my dear friend, in this topsy-turvy world of mine, I must ask: do you prefer your chocolate to be dark as the night or as milky as a moonbeam?'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatObj.eval(\"I want oolong tea. And a chocolate.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T18:40:22.026108Z",
     "start_time": "2023-09-26T18:40:18.130511Z"
    }
   },
   "id": "2fd057fbdae0dc17"
  },
  {
   "cell_type": "markdown",
   "id": "edf190287af42e48",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "------\n",
    "\n",
    "## References\n",
    "\n",
    "### Articles\n",
    "\n",
    "[AA1] Anton Antonov,\n",
    "[\"Workflows with LLM functions\"](https://rakuforprediction.wordpress.com/2023/08/01/workflows-with-llm-functions/),\n",
    "(2023),\n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com).\n",
    "\n",
    "[SW1] Stephen Wolfram,\n",
    "[\"The New World of LLM Functions: Integrating LLM Technology into the Wolfram Language\"](https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/),\n",
    "(2023),\n",
    "[Stephen Wolfram Writings](https://writings.stephenwolfram.com).\n",
    "\n",
    "[SW2] Stephen Wolfram,\n",
    "[\"Prompts for Work & Play: Launching the Wolfram Prompt Repository\"](https://writings.stephenwolfram.com/2023/06/prompts-for-work-play-launching-the-wolfram-prompt-repository/),\n",
    "(2023),\n",
    "[Stephen Wolfram Writings](https://writings.stephenwolfram.com).\n",
    "\n",
    "### Packages, paclets, repositories\n",
    "\n",
    "[AAp1] Anton Antonov,\n",
    "[LLMPrompts Python package](hhttps://github.com/antononcube/Python-packages/tree/main/LLMPrompts),\n",
    "(2023),\n",
    "[Python-packages at GitHub/antononcube](https://github.com/antononcube/Python-packages).\n",
    "\n",
    "[AAp2] Anton Antonov,\n",
    "[LLMFunctionObjects Python package](https://github.com/antononcube/Python-packages/tree/main/LLMFunctionObjects),\n",
    "(2023),\n",
    "[Python-packages at GitHub/antononcube](https://github.com/antononcube/Python-packages).\n",
    "\n",
    "[AAp3] Anton Antonov,\n",
    "[LLM::Prompts Raku package](https://github.com/antononcube/Raku-LLM-Prompts),\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp4] Anton Antonov,\n",
    "[LLM::Functions Raku package](https://github.com/antononcube/Raku-LLM-Functions),\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp5] Anton Antonov,\n",
    "[Jupyter::Chatbook Raku package](https://github.com/antononcube/Raku-Jupyter-Chatbook),\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[WRIr1] Wolfram Research, Inc.,\n",
    "[Wolfram Prompt Repository](https://resources.wolframcloud.com/PromptRepository)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciPyCentric",
   "language": "python",
   "name": "scipycentric"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
